{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Learning_Practice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7gs6M-Ye-2C"
      },
      "source": [
        "# **Ensemble Learning in Practice**\n",
        "\n",
        "This notebook covers implementations of main ensemble learning techniques: voting, averaging, stacking, bagging and boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-7VQihYghsf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostRegressor"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPprQUBdgST5"
      },
      "source": [
        "## **1. Voting (Hard voting)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrXUUqw7oSbY",
        "outputId": "e2007ca7-aa23-44b7-9693-d0baf153f864"
      },
      "source": [
        "# Create dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=5)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize individual models\n",
        "clf_1 = KNeighborsClassifier()\n",
        "clf_2 = LogisticRegression()\n",
        "clf_3 = DecisionTreeClassifier()\n",
        "\n",
        "# Create voting classifier\n",
        "voting_ens = VotingClassifier(\n",
        "    estimators=[('knn', clf_1), ('lr', clf_2), ('dt', clf_3)], voting='hard')\n",
        "\n",
        "for clf in (clf_1, clf_2, clf_3, voting_ens):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier 0.9385\n",
            "LogisticRegression 0.929\n",
            "DecisionTreeClassifier 0.932\n",
            "VotingClassifier 0.942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-3S9z9abgLU"
      },
      "source": [
        "## **2. Averaging (Soft voting)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQmY4DuV0EKz",
        "outputId": "60df2101-50df-4fb5-8703-b836b2133371"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) \n",
        "\n",
        "# Initialize individual models\n",
        "reg1 = DecisionTreeRegressor()\n",
        "reg2 = LinearRegression()\n",
        "\n",
        "# Create voting regressor\n",
        "voting_ens = VotingRegressor(estimators=[('dt', reg1), ('lr', reg2)], weights=[2,1])\n",
        "\n",
        "# Fit and predict with the models and enseble\n",
        "for reg in (reg1, reg2, voting_ens):\n",
        "   reg.fit(X_train, y_train)\n",
        "   y_pred = reg.predict(X_test)\n",
        "   print(reg.__class__.__name__, mean_absolute_error(y_test, y_pred))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeRegressor 3.0392156862745106\n",
            "LinearRegression 3.2648171537970883\n",
            "VotingRegressor 2.5586572390061875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBnhzr5ubSp5"
      },
      "source": [
        "## **3. Stacking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhfK1w0Ac4yH"
      },
      "source": [
        "# Standard Stacking for Classification\n",
        "from mlxtend.classifier import StackingClassifier"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0pCXhA8bvrT",
        "outputId": "6a63b64f-f572-466f-c35b-1364dac538af"
      },
      "source": [
        "# Create dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=15)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize individual models\n",
        "clf_1 = KNeighborsClassifier()\n",
        "clf_2 = GaussianNB()\n",
        "clf_3 = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize meta-model\n",
        "clf_meta = LogisticRegression()\n",
        "\n",
        "# Create stacking classifier\n",
        "clf_stack = StackingClassifier(classifiers=[clf_1, clf_2, clf_3], \n",
        "                               meta_classifier=clf_meta,\n",
        "                               use_probas=False,  \n",
        "                               use_features_in_secondary=False)\n",
        "\n",
        "for clf in (clf_1, clf_2, clf_3, clf_meta, clf_stack):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier 0.84\n",
            "GaussianNB 0.8395\n",
            "DecisionTreeClassifier 0.895\n",
            "LogisticRegression 0.8595\n",
            "StackingClassifier 0.898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCtwCAKidfYh"
      },
      "source": [
        "# Stacking with cross-validation for regression\n",
        "from mlxtend.regressor import StackingCVRegressor"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VTUiF6egOMx",
        "outputId": "917ed8fc-14b8-406f-cb49-a7f147a61cfd"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) \n",
        "\n",
        "# Initialize individual models\n",
        "reg1 = DecisionTreeRegressor()\n",
        "reg2 = SVR()\n",
        "\n",
        "# Create meta-model \n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Create stacking classifier\n",
        "reg_stack = StackingCVRegressor(regressors=[reg1, reg2], \n",
        "                               meta_regressor=meta_model,\n",
        "                               use_features_in_secondary=False)\n",
        "\n",
        "for reg in (reg1, reg2, meta_model, reg_stack):\n",
        "  reg.fit(X_train, y_train)\n",
        "  y_pred = reg.predict(X_test)\n",
        "  print(reg.__class__.__name__, mean_absolute_error(y_test, y_pred))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeRegressor 3.327450980392158\n",
            "SVR 5.222470732130654\n",
            "LinearRegression 3.2191778452433755\n",
            "StackingCVRegressor 2.933358665677874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa2mdddwjiOO"
      },
      "source": [
        "## **4. Bagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKrbVylWkXlf"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h09_xMnQjvEB",
        "outputId": "0dfd779f-1d0f-4909-cc69-d648e5592383"
      },
      "source": [
        "# Create dataset\n",
        "X, y = make_classification(n_samples=10000, n_features=5)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize weak model \n",
        "base_model = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Create bagging classifier\n",
        "clf_bagging = BaggingClassifier(base_estimator=base_model, n_estimators=100, oob_score=True)\n",
        "\n",
        "clf_bagging.fit(X_train, y_train)\n",
        "print(clf_bagging.oob_score_)\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.918625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "969b5jgmk6Ke",
        "outputId": "f27e0061-52b1-4db6-bc2a-2b6218764111"
      },
      "source": [
        "pred = clf_bagging.predict(X_test)\n",
        "print(accuracy_score(y_test, pred))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Z_-G2Smrx4"
      },
      "source": [
        "## **5. Boosting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiR9hZtSnaKb"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQr_aMV9msgG"
      },
      "source": [
        "from sklearn.datasets import load_boston\n",
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20) "
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdFhA1Tok7W3",
        "outputId": "414776aa-4a28-4b4d-d506-c35ff084d937"
      },
      "source": [
        "# Initialize weak model \n",
        "base_model = LinearRegression(normalize=True)\n",
        "\n",
        "# Create AdaBoost regressor\n",
        "reg_adaboost = AdaBoostRegressor(base_estimator=base_model, n_estimators=100, random_state=500)\n",
        "reg_adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compare with y_test\n",
        "pred = reg_adaboost.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, pred))\n",
        "print('RMSE:', rmse)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.1854762804154415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJUkNlp3nkKI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}